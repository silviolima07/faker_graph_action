# -*- coding: utf-8 -*-
"""caged_tab4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FDfMIVUrmyNwoY1VpQDKUrr8Wv7glYZW
"""

import pandas as pd
import numpy as np
import requests
import io
from bs4 import BeautifulSoup
import urllib.request

url_caged = "http://pdet.mte.gov.br/novo-caged"
parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed
resp = urllib.request.urlopen(url_caged)
soup = BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))
url_tabela='http://pdet.mte.gov.br'
for link in soup.find_all('a', href=True):
  if "tabelas.xlsx" in link['href']:
        #print("Link:",link['href'])
        #print("Url tabela: ", url_tabela+str(link['href']))
        url_tabela = url_tabela+str(link['href'])

def excel_to_pandas2(URL, local_path, sheet, header):
    resp = requests.get(URL)
    with open(local_path, 'wb') as output:
        output.write(resp.content)
    df = pd.read_excel(local_path,sheet_name=sheet,header=header)
    return df

df_tab4 = excel_to_pandas2(url_tabela,'caged_tabela4.xlsx', 'Tabela 4',[2])

temp = excel_to_pandas2(url_tabela,'caged_tabela4.xlsx', 'Tabela 4',[1])

temp1 = temp.columns.to_list()[1:2]
print(temp1)
data = str(temp1).split('-')[1].strip().split("EM ")[1].replace(' DE ','_').lower()
data

df_tab4.drop(columns=['Unnamed: 0'], inplace=True)

#df_tab4

df_tab4.columns = df_tab4.iloc[2]

df_tab4.rename(columns={np.nan: 'Atividade'}, inplace=True)

#df_tab4

df_tab4.dropna(inplace=True)

df_tab4 = df_tab4.loc[df_tab4.Atividade != 'Total']

df_tab4['data'] = data

#df_tab4.to_csv("df_caged_tab4_"+data+".csv", index=False, encoding='utf-8')
df_tab4.to_csv("df_caged_tab4.csv", index=False, encoding='utf-8')